{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JDOx4VJSh7jH"
      },
      "outputs": [],
      "source": [
        "#Importing required libraries\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vACSsZrCQO4y"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, MaxPool2D, Flatten, BatchNormalization\n",
        "\n",
        "from keras.preprocessing.image import array_to_img, load_img\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "dOK2N6Wre1mW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiKJLoksm_4_",
        "outputId": "ec2407c7-0dd5-4c95-e3c7-86601a3379bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/128.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.14.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.11.17)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "#Importing keras hyperparameter tuning library\n",
        "!pip install keras-tuner\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gkE6pNL3nFO0"
      },
      "outputs": [],
      "source": [
        "from keras_tuner import HyperParameters, RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELHxEf0ZRrR5",
        "outputId": "6a6e87fb-6044-47bc-c1dd-7d005bf12f94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 1602s 9us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vjwto53Tjyfn"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "#Assuming y_train is a 1D array of class labels\n",
        "num_classes = 10  # Adjust to the number of classes in your problem\n",
        "y_train_one_hot = to_categorical(y_train, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HeW2s9fO8jGN"
      },
      "outputs": [],
      "source": [
        "#Create one hot ecoded test class of labels\n",
        "\n",
        "y_test_one_hot = to_categorical(y_test, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ndweHSkRV-lq"
      },
      "outputs": [],
      "source": [
        "#Instantiate a sequential model\n",
        "\n",
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CljNMt2tX2J_",
        "outputId": "3f5e6cb2-0149-4d9b-915a-416ccc13f256"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (10000, 32, 32, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#Examining the feature arrays\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "kdelBBjgYnhj",
        "outputId": "7977ceb2-908f-41ef-8117-c1c38211a40b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Examining one array in the test set\n",
        "\n",
        "pic = array_to_img(X_train[6754])\n",
        "display(pic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWLoFOyvZbwm",
        "outputId": "ab4abcad-f37a-476b-8dd7-2c2b02a27f50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 1), (10000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#Examining the label arrays\n",
        "\n",
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBi74tCTZpTq",
        "outputId": "f2f1da24-ade4-46ac-86b4-d0cad126186b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "y_train[6754]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an EarlyStopping callback with a monitor set to 'val_loss'\n",
        "# This callback will monitor the validation loss during training\n",
        "# If the validation loss does not improve for 5 consecutive epochs (patience=5),\n",
        "# training will be stopped early to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "metadata": {
        "id": "eNAo5UU4MhKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional layer with 128 filters, kernel size 3, input shape (32, 32, 3), ReLU activation, and same padding\n",
        "model.add(Conv2D(128, kernel_size=3, input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
        "\n",
        "# Dropout layer with a dropout rate of 0.5\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Convolutional layer with 64 filters, kernel size 3, ReLU activation, and same padding\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', padding='same'))\n",
        "\n",
        "# Dropout layer with a dropout rate of 0.25\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Another convolutional layer with 64 filters, kernel size 3, ReLU activation, and same padding\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', padding='same'))\n",
        "\n",
        "# Dropout layer with a dropout rate of 0.25\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Another convolutional layer with 32 filters, kernel size 3, ReLU activation, and same padding\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu', padding='same'))\n",
        "\n",
        "# Dropout layer with a dropout rate of 0.25\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Another convolutional layer with 16 filters, kernel size 3, ReLU activation, and same padding\n",
        "model.add(Conv2D(16, kernel_size=3, activation='relu', padding='same'))\n",
        "\n",
        "# Flatten layer to convert the 3D feature maps to 1D feature vectors\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense (fully connected) layer with 10 units and softmax activation for multiclass classification\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model with the Adam optimizer, categorical crossentropy loss, and accuracy metric\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training data (X_train) with corresponding one-hot encoded labels (y_train_one_hot)\n",
        "# for 100 epochs, using 20% of the data for validation, and early stopping callback\n",
        "history = model.fit(X_train, y_train_one_hot, epochs=100, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Plotting the training and validation accuracy over epochs\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'])"
      ],
      "metadata": {
        "id": "xbVnZQM4LovJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional layer with 32 filters, kernel size (3, 3), ReLU activation, and input shape (32, 32, 3)\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "\n",
        "# Batch Normalization layer to normalize and stabilize activations\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Dropout layer with a dropout rate of 0.25 to prevent overfitting\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# MaxPooling layer with pool size (2, 2) to downsample the spatial dimensions\n",
        "model.add(MaxPool2D((2, 2)))\n",
        "\n",
        "# Another Convolutional layer with 64 filters, kernel size (3, 3), and ReLU activation\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Another Batch Normalization layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Another Dropout layer with a dropout rate of 0.25\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Another MaxPooling layer\n",
        "model.add(MaxPool2D((2, 2)))\n",
        "\n",
        "# Another Convolutional layer with 64 filters, kernel size (3, 3), and ReLU activation\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Another Batch Normalization layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Flatten layer to convert the 3D feature maps to 1D feature vectors\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully connected layer with 64 units and ReLU activation\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer with 10 units (for 10 classes) and softmax activation for multiclass classification\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model with the Adam optimizer, categorical crossentropy loss, and accuracy metric\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training data (x_train) with corresponding one-hot encoded labels (y_train_one_hot)\n",
        "# for 100 epochs, using 20% of the data for validation, and early stopping callback\n",
        "history = model.fit(X_train, y_train_one_hot, epochs=100, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Plotting the training and validation accuracy over epochs\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'])"
      ],
      "metadata": {
        "id": "dwKx8G6kUZsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_vdRmCZkTk_"
      },
      "outputs": [],
      "source": [
        "#Creating a single test sample, adding an extra dimension to the selected sample using np.expand_dims\n",
        "\n",
        "test = np.expand_dims(X_test[3], axis=0)\n",
        "\n",
        "#Generating predicting classes\n",
        "\n",
        "model.predict(test)\n",
        "\n",
        "# Get the predicted classes\n",
        "predicted_class = predictions.argmax(axis=1)\n",
        "predicted_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3Z4vjt1lqDP"
      },
      "outputs": [],
      "source": [
        "#Creating a single test sample, adding an extra dimension to the selected sample using np.expand_dims\n",
        "\n",
        "test2 = np.expand_dims(X_test[765], axis=0)\n",
        "\n",
        "#Generating predicting classes\n",
        "\n",
        "predictions = model.predict(test2)\n",
        "\n",
        "# Get the predicted classes\n",
        "predicted_classes = predictions.argmax(axis=1)\n",
        "predicted_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jr8jTUk4lp40"
      },
      "outputs": [],
      "source": [
        "#saving model\n",
        "\n",
        "model.save(\"my_model.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO4uI_j3gS5v"
      },
      "source": [
        "#Hyper Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to build a convolutional neural network (CNN) model with hyperparameter tuning\n",
        "def build_model(hp):\n",
        "    # Initialize a Sequential model\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add the first convolutional layer with tunable parameters\n",
        "    model.add(\n",
        "        Conv2D(\n",
        "            filters=hp.Int(\"first_layer_unit\", min_value=32, max_value=512, step=32),\n",
        "            kernel_size=hp.Int(\"kernel_size\", min_value=2, max_value=4, step=1),\n",
        "            activation=\"relu\",\n",
        "            input_shape=(32, 32, 3),\n",
        "            padding=hp.Choice(\"padding\", [\"valid\", \"same\"])\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Add BatchNormalization to normalize and stabilize activations\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Tune the number of additional layers dynamically\n",
        "    for i in range(hp.Int(\"num_layers\", 1, 9)):\n",
        "        # Add convolutional layers with tunable parameters\n",
        "        model.add(\n",
        "            Conv2D(\n",
        "                filters=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
        "                activation=\"relu\",\n",
        "                padding=hp.Choice(\"padding\", [\"valid\", \"same\"]),\n",
        "                kernel_size=hp.Int(\"kernel_size\", min_value=2, max_value=4, step=1)\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Add Dropout layer if specified in hyperparameters\n",
        "    if hp.Boolean(\"dropout\"):\n",
        "        model.add(Dropout(rate=0.25))\n",
        "\n",
        "    # Flatten the output to prepare for fully connected layers\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Add a dense layer with 10 units (for 10 classes) and softmax activation for multiclass classification\n",
        "    model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    # Tune the learning rate using logarithmic sampling\n",
        "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
        "\n",
        "    # Compile the model with the Adam optimizer, categorical crossentropy loss, and accuracy metric\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    # Return the compiled model\n",
        "    return model\n",
        "\n",
        "\n",
        "# Instantiate the build_model function with default hyperparameters for demonstration\n",
        "build_model(HyperParameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YXduEL7b9_K",
        "outputId": "d6c72322-dfd1-4dbc-872e-e877e1f1fa94"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.engine.sequential.Sequential at 0x7940b03727d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tuner using RandomSearch\n",
        "tuner = RandomSearch(\n",
        "    hypermodel=build_model,          # The hypermodel to be tuned, in this case, the build_model function\n",
        "    objective=\"val_accuracy\",        # The metric to optimize during hyperparameter search (validation accuracy)\n",
        "    max_trials=5,                     # The total number of trials (different sets of hyperparameters) to run\n",
        "    executions_per_trial=1,          # The number of times to train the model with different initializations for each trial\n",
        "    overwrite=True,                   # Whether to overwrite the results of a previous tuning session in the same directory\n",
        "    directory=\"my_dir\",               # The directory to store the tuning results\n",
        "    project_name=\"cifar_classification\")  # The name of the tuning project, used to organize results within the directory"
      ],
      "metadata": {
        "id": "w9TwTFYxcmY4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf2IMJXEqdIM",
        "outputId": "c4d2d2e3-2da4-4833-f4d7-e708754b03f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 7\n",
            "first_layer_unit (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
            "kernel_size (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 4, 'step': 1, 'sampling': 'linear'}\n",
            "padding (Choice)\n",
            "{'default': 'valid', 'conditions': [], 'values': ['valid', 'same'], 'ordered': False}\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 9, 'step': 1, 'sampling': 'linear'}\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
            "dropout (Boolean)\n",
            "{'default': False, 'conditions': []}\n",
            "lr (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
          ]
        }
      ],
      "source": [
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZNyw7anwPGb",
        "outputId": "ca8088c1-31df-41ca-8490-26b5dbabfb2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 13m 24s]\n",
            "val_accuracy: 0.5575000047683716\n",
            "\n",
            "Best val_accuracy So Far: 0.678600013256073\n",
            "Total elapsed time: 00h 47m 14s\n"
          ]
        }
      ],
      "source": [
        "tuner.search(X_train, y_train_one_hot, epochs=10, validation_split=0.2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}